{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f81a94-9c83-4811-b6c3-6efa5578be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "\n",
    "from Model_A_Dataset import Model_A_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26491b63-3bbd-4328-8567-3e9f2b562560",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19dd6702-c325-4ff0-b44a-1ca2a45ff723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5993f-e338-487c-be7e-0be2aebbb316",
   "metadata": {},
   "source": [
    "## Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "670908fe-f85f-4023-966b-bd918f3aa1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_train = pd.read_csv('../data/data_entries/miccai2023_nih-cxr-lt_labels_train.csv')\n",
    "df_val = pd.read_csv('../data/data_entries/miccai2023_nih-cxr-lt_labels_val.csv')\n",
    "df_test = pd.read_csv('../data/data_entries/miccai2023_nih-cxr-lt_labels_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee858d8a-ad28-4289-83bc-7e76938435d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image directories\n",
    "image_dir_train = '../data/train_images'\n",
    "image_dir_test = '../data/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227769a7-75cc-4c27-9f1d-4b991c8fbb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_image_ids(df, image_dir):\n",
    "    image_files = set(os.listdir(image_dir))\n",
    "    return df[df['id'].isin(image_files)]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee30625-1d28-4d80-a5ca-1365604f34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid images, only images where their IDs find in the image folder\n",
    "valid_train_ids = get_valid_image_ids(df_train, image_dir_train)\n",
    "valid_val_ids = get_valid_image_ids(df_val, image_dir_train)\n",
    "valid_test_ids = get_valid_image_ids(df_test, image_dir_test)\n",
    "\n",
    "df_train_valid = df_train[df_train['id'].isin(valid_train_ids)]\n",
    "df_val_valid = df_val[df_val['id'].isin(valid_val_ids)]\n",
    "df_test_valid = df_test[df_test['id'].isin(valid_test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8db0355-5fdf-4d4e-9d68-934950e9f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val = pd.concat([df_train_valid, df_val_valid], ignore_index=True)\n",
    "assert df_train_val.shape[0] == df_train_valid.shape[0] + df_val_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217aad6d-102c-4cac-8ac7-59c167e3e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop subj_id\n",
    "df_train_val = df_train_val.copy()\n",
    "df_train_val.drop(columns=['subj_id'], inplace=True)\n",
    "\n",
    "df_test_valid = df_test_valid.copy()\n",
    "df_test_valid.drop(columns=['subj_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002828f8-be32-4a86-8288-8d6525fdc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inconsistent rows ( row has No Finding 1 and other categories 1)\n",
    "inconsistent_rows = df_train_val[(df_train_val['No Finding'] == 1) & (df_train_val.iloc[:, 1:-1].sum(axis=1) > 0)]\n",
    "assert len(inconsistent_rows) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd8de3e-ec4e-4738-ad65-f4fab0346d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'No Finding': 0, 'Finding': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01c2ca6-8e58-4c5c-a144-49652fba5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0df02d5-c079-49ca-97aa-f3b67f7cc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Subset of the dataset using stratification on 'No Finding'\n",
    "df_half, _ = train_test_split(\n",
    "    df_train_val, test_size=0.2, stratify=df_train_val['No Finding'], random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split the subset into training (80%) and validation (20%) sets, also stratified on 'No Finding'\n",
    "df_train, df_val = train_test_split(\n",
    "    df_half, test_size=0.2, stratify=df_half['No Finding'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fa0405c-c2ae-4812-b61b-7adf0a581075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55375, 21), (13844, 21))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3728621e-9bb4-46ab-b583-c31933aaf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = Model_A_Dataset(df_train, image_dir_train, category_mapping, transform=train_transform)\n",
    "val_dataset = Model_A_Dataset(df_val, image_dir_train, category_mapping, transform=val_transform)\n",
    "test_dataset = Model_A_Dataset(df_test_valid, image_dir_test, category_mapping, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c351d584-1941-4c47-9696-a27f22a2610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec2bc0b-ca1e-48ad-8cc3-e36a3de70b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022b544e-2e18-473b-89af-fe806b67639a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1731, 433, 659)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1f22b7-cbf4-4bdc-af1f-795d16097f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: 00022949_001.png\n",
      "Label: 1\n",
      "Image Shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "img, label, img_id = train_dataset[1]\n",
    "print(f\"Image ID: {img_id}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Image Shape: {img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c7c4b00-1ca2-46ff-9e85-34220ccc2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>...</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pneumoperitoneum</th>\n",
       "      <th>Pneumomediastinum</th>\n",
       "      <th>Subcutaneous Emphysema</th>\n",
       "      <th>Tortuous Aorta</th>\n",
       "      <th>Calcification of the Aorta</th>\n",
       "      <th>No Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68218</th>\n",
       "      <td>00022949_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "68218  00022949_001.png            0             0              0      0   \n",
       "\n",
       "       Effusion  Emphysema  Fibrosis  Hernia  Infiltration  ...  Nodule  \\\n",
       "68218         1          0         0       0             1  ...       0   \n",
       "\n",
       "       Pleural Thickening  Pneumonia  Pneumothorax  Pneumoperitoneum  \\\n",
       "68218                   0          1             0                 0   \n",
       "\n",
       "       Pneumomediastinum  Subcutaneous Emphysema  Tortuous Aorta  \\\n",
       "68218                  0                       0               0   \n",
       "\n",
       "       Calcification of the Aorta  No Finding  \n",
       "68218                           0           0  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.id == img_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704a044-c24c-464f-a9cb-fd78074319dc",
   "metadata": {},
   "source": [
    "## Define train, validate and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b0a530-58c8-4ec4-88f5-25677b70dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels, _ in tqdm(dataloader, desc=\"Training\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Ensure labels are of type float32 and reshape to [batch_size, 1]\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and labels for dynamic threshold calculation\n",
    "        all_preds.append(outputs.detach().cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Flatten predictions and labels\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Find the best threshold based on F1 score\n",
    "    thresholds = np.arange(0.4, 1.0, 0.025)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = (all_preds > threshold).astype(float)\n",
    "        f1 = f1_score(all_labels, preds, average='binary')\n",
    "        accuracy = accuracy_score(all_labels, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return avg_loss, best_accuracy, best_f1, best_threshold,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51ffa175-4836-4817-95a7-948607017433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, threshold):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Ensure labels are of type float32 and reshape to [batch_size, 1]\n",
    "            labels = labels.view(-1, 1).float()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = (outputs > threshold).float()\n",
    "            correct += (preds == labels).all(dim=1).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Collect predictions and labels for F1 score calculation\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    \n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8268332c-a430-4650-9733-f3f2d552562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device, threshold):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.view(-1, 1).float()\n",
    "            outputs = model(images)\n",
    "            preds = (outputs > threshold).float().cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return all_preds, all_labels, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546933b0-3be1-4633-ad99-6a229958776b",
   "metadata": {},
   "source": [
    "## Define the model: train, validate and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45884255-384b-4b9c-8a48-d8711c0ded5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet152(weights='IMAGENET1K_V2') \n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(), \n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd9eeb02-66b6-47f0-826d-7ad6939e22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer, loss, and metrics\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler with a gentler decay\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eb6b169-0cbc-4c45-a1d6-25b48160a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and model saving\n",
    "best_f1 = float(\"inf\")\n",
    "patience = 7\n",
    "counter = 0\n",
    "\n",
    "best_model_path = \"best_model_a_v3.pth\"\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d7b007-a0db-4f20-9646-e41f9169f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6141, F1: 0.6272, Accuracy: 0.6581, Threshold: 0.4\n",
      "Val Loss: 0.6060, F1: 0.6257\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:39<00:00,  4.33it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6070, F1: 0.6355, Accuracy: 0.6673, Threshold: 0.4\n",
      "Val Loss: 0.6001, F1: 0.6476\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:38<00:00,  4.34it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6011, F1: 0.6421, Accuracy: 0.6742, Threshold: 0.4\n",
      "Val Loss: 0.6277, F1: 0.6477\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:36<00:00,  4.37it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5958, F1: 0.6480, Accuracy: 0.6752, Threshold: 0.4\n",
      "Val Loss: 0.6167, F1: 0.6166\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:36<00:00,  4.37it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:06<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5950, F1: 0.6490, Accuracy: 0.6783, Threshold: 0.4\n",
      "Val Loss: 0.5969, F1: 0.6251\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:38<00:00,  4.34it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5884, F1: 0.6537, Accuracy: 0.6819, Threshold: 0.4\n",
      "Val Loss: 0.5941, F1: 0.6274\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:37<00:00,  4.36it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5857, F1: 0.6568, Accuracy: 0.6879, Threshold: 0.4\n",
      "Val Loss: 0.5883, F1: 0.6402\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:39<00:00,  4.33it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5823, F1: 0.6584, Accuracy: 0.6889, Threshold: 0.4\n",
      "Val Loss: 0.5880, F1: 0.6395\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:37<00:00,  4.36it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5807, F1: 0.6623, Accuracy: 0.6940, Threshold: 0.4\n",
      "Val Loss: 0.5872, F1: 0.6604\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:38<00:00,  4.34it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5755, F1: 0.6669, Accuracy: 0.6959, Threshold: 0.4\n",
      "Val Loss: 0.5887, F1: 0.6521\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5713, F1: 0.6720, Accuracy: 0.6989, Threshold: 0.4\n",
      "Val Loss: 0.5860, F1: 0.6537\n",
      "Validation F1 improved. Saving model...\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:37<00:00,  4.35it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5655, F1: 0.6742, Accuracy: 0.7010, Threshold: 0.4\n",
      "Val Loss: 0.5882, F1: 0.6511\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5607, F1: 0.6813, Accuracy: 0.7058, Threshold: 0.4\n",
      "Val Loss: 0.5962, F1: 0.6461\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5547, F1: 0.6856, Accuracy: 0.7122, Threshold: 0.4\n",
      "Val Loss: 0.5919, F1: 0.6416\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5479, F1: 0.6919, Accuracy: 0.7168, Threshold: 0.4\n",
      "Val Loss: 0.5953, F1: 0.6531\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:37<00:00,  4.36it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5354, F1: 0.7009, Accuracy: 0.7267, Threshold: 0.4\n",
      "Val Loss: 0.5988, F1: 0.6418\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5220, F1: 0.7117, Accuracy: 0.7355, Threshold: 0.4\n",
      "Val Loss: 0.6006, F1: 0.6533\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1731/1731 [06:35<00:00,  4.38it/s]\n",
      "Validating: 100%|██████████| 433/433 [01:05<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5077, F1: 0.7243, Accuracy: 0.7460, Threshold: 0.4\n",
      "Val Loss: 0.6166, F1: 0.6473\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and validation\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_acc, train_f1, best_threshold = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_f1 = validate(model, val_loader, criterion, device, best_threshold)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, F1: {train_f1:.4f}, Accuracy: {train_acc:.4f}, Threshold: {best_threshold}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Early stopping logic\n",
    "    if val_loss < best_f1:\n",
    "        print(\"Validation F1 improved. Saving model...\")\n",
    "        best_f1 = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print('-' * 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b3788f-5515-47cf-b769-e0fb67b14002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b134793-0109-4524-b1e5-daa62f927201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 659/659 [01:38<00:00,  6.67it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds, all_labels, test_f1 = test(model, test_loader, device, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a96f9ecb-2433-4b92-8c27-97663a113e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.7945465002198994\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test F1: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fdbb30e-89b2-460a-b4d2-72c509dbacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Micro: 0.7119206868744367, F1 Macro: 0.6563385520221927\n",
      "Precision: 0.7118190441523605, Recall: 0.6530530158371544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Calculate F1 score (micro and macro)\n",
    "f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"F1 Micro: {f1_micro}, F1 Macro: {f1_macro}\")\n",
    "\n",
    "# Precision and recall\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "print(f\"Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0f9fd05-16f5-44cd-a2ce-c633a85273e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No Finding       0.71      0.41      0.52      8015\n",
      "     Finding       0.71      0.90      0.79     13066\n",
      "\n",
      "    accuracy                           0.71     21081\n",
      "   macro avg       0.71      0.65      0.66     21081\n",
      "weighted avg       0.71      0.71      0.69     21081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=category_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0a4afab-d7ba-48e1-956e-346eaf0768d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n",
      "True: [0.], Predicted: [1.]\n",
      "True: [1.], Predicted: [1.]\n"
     ]
    }
   ],
   "source": [
    "# Visualize a few predictions and their true labels\n",
    "for i in range(10):  # Show 5 examples\n",
    "    print(f\"True: {all_labels[i]}, Predicted: {all_preds[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb285d-4454-4a08-a8b9-cf4a65f46c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
